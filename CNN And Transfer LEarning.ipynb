{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating CNN Using Scratch And Transfer Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Please download the dataset from the below url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the libraries as shown below\n",
    "\n",
    "from tensorflow.keras.layers import Input, Lambda, Dense, Flatten,Conv2D\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.applications.vgg19 import VGG19\n",
    "from tensorflow.keras.applications.resnet50 import preprocess_input\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator,load_img\n",
    "from tensorflow.keras.models import Sequential\n",
    "import numpy as np\n",
    "from glob import glob\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# re-size all the images to this\n",
    "IMAGE_SIZE = [224, 224]\n",
    "\n",
    "train_path = 'Dataset/train'\n",
    "valid_path = 'Dataset/test'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the Vgg 16 library as shown below and add preprocessing layer to the front of VGG\n",
    "# Here we will be using imagenet weights\n",
    "\n",
    "mobilnet = VGG19(input_shape=IMAGE_SIZE + [3], weights='imagenet', include_top=False)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# don't train existing weights\n",
    "for layer in mobilnet.layers:\n",
    "    layer.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "  # useful for getting number of output classes\n",
    "folders = glob('Dataset/train/*')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Dataset/train/Parasitized', 'Dataset/train/Uninfected']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "folders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# our layers - you can add more if you want\n",
    "x = Flatten()(mobilnet.output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = Dense(len(folders), activation='softmax')(x)\n",
    "\n",
    "# create a model object\n",
    "model = Model(inputs=mobilnet.input, outputs=prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         [(None, 224, 224, 3)]     0         \n",
      "_________________________________________________________________\n",
      "block1_conv1 (Conv2D)        (None, 224, 224, 64)      1792      \n",
      "_________________________________________________________________\n",
      "block1_conv2 (Conv2D)        (None, 224, 224, 64)      36928     \n",
      "_________________________________________________________________\n",
      "block1_pool (MaxPooling2D)   (None, 112, 112, 64)      0         \n",
      "_________________________________________________________________\n",
      "block2_conv1 (Conv2D)        (None, 112, 112, 128)     73856     \n",
      "_________________________________________________________________\n",
      "block2_conv2 (Conv2D)        (None, 112, 112, 128)     147584    \n",
      "_________________________________________________________________\n",
      "block2_pool (MaxPooling2D)   (None, 56, 56, 128)       0         \n",
      "_________________________________________________________________\n",
      "block3_conv1 (Conv2D)        (None, 56, 56, 256)       295168    \n",
      "_________________________________________________________________\n",
      "block3_conv2 (Conv2D)        (None, 56, 56, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_conv3 (Conv2D)        (None, 56, 56, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_conv4 (Conv2D)        (None, 56, 56, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_pool (MaxPooling2D)   (None, 28, 28, 256)       0         \n",
      "_________________________________________________________________\n",
      "block4_conv1 (Conv2D)        (None, 28, 28, 512)       1180160   \n",
      "_________________________________________________________________\n",
      "block4_conv2 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv3 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv4 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_pool (MaxPooling2D)   (None, 14, 14, 512)       0         \n",
      "_________________________________________________________________\n",
      "block5_conv1 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv2 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv3 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv4 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_pool (MaxPooling2D)   (None, 7, 7, 512)         0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 25088)             0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 2)                 50178     \n",
      "=================================================================\n",
      "Total params: 20,074,562\n",
      "Trainable params: 50,178\n",
      "Non-trainable params: 20,024,384\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# view the structure of the model\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import MaxPooling2D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 224, 224, 16)      208       \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 112, 112, 16)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 112, 112, 32)      2080      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 56, 56, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 56, 56, 64)        8256      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 28, 28, 64)        0         \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 50176)             0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 500)               25088500  \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 2)                 1002      \n",
      "=================================================================\n",
      "Total params: 25,100,046\n",
      "Trainable params: 25,100,046\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "### Create Model from scratch using CNN\n",
    "model=Sequential()\n",
    "model.add(Conv2D(filters=16,kernel_size=2,padding=\"same\",activation=\"relu\",input_shape=(224,224,3)))\n",
    "model.add(MaxPooling2D(pool_size=2))\n",
    "model.add(Conv2D(filters=32,kernel_size=2,padding=\"same\",activation =\"relu\"))\n",
    "model.add(MaxPooling2D(pool_size=2))\n",
    "model.add(Conv2D(filters=64,kernel_size=2,padding=\"same\",activation=\"relu\"))\n",
    "model.add(MaxPooling2D(pool_size=2))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(500,activation=\"relu\"))\n",
    "model.add(Dense(2,activation=\"softmax\"))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tell the model what cost and optimization method to use\n",
    "model.compile(\n",
    "  loss='categorical_crossentropy',\n",
    "  optimizer='adam',\n",
    "  metrics=['accuracy']\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the Image Data Generator to import the images from the dataset\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "train_datagen = ImageDataGenerator(rescale = 1./255,\n",
    "                                   shear_range = 0.2,\n",
    "                                   zoom_range = 0.2,\n",
    "                                   horizontal_flip = True)\n",
    "\n",
    "test_datagen = ImageDataGenerator(rescale = 1./255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 27558 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "# Make sure you provide the same target size as initialied for the image size\n",
    "training_set = train_datagen.flow_from_directory('Dataset/train',\n",
    "                                                 target_size = (224, 224),\n",
    "                                                 batch_size = 32,\n",
    "                                                 class_mode = 'categorical')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras_preprocessing.image.directory_iterator.DirectoryIterator at 0x7fabfc70a250>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 134 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "test_set = test_datagen.flow_from_directory('Dataset/test',\n",
    "                                            target_size = (224, 224),\n",
    "                                            batch_size = 32,\n",
    "                                            class_mode = 'categorical')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "862/862 [==============================] - 997s 1s/step - loss: 0.3477 - accuracy: 0.8620 - val_loss: 0.6606 - val_accuracy: 0.6940\n",
      "Epoch 2/5\n",
      "120/862 [===>..........................] - ETA: 14:44 - loss: 0.2370 - accuracy: 0.9206"
     ]
    }
   ],
   "source": [
    "# fit the model\n",
    "# Run the cell. It will take some time to execute\n",
    "r = model.fit(\n",
    "  training_set,\n",
    "  validation_data=test_set,\n",
    "  epochs=5,\n",
    "  steps_per_epoch=len(training_set),\n",
    "  validation_steps=len(test_set)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'r' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-19-bb6bf5bcc936>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# plot the loss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'loss'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'train loss'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'val_loss'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'val loss'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'r' is not defined"
     ]
    }
   ],
   "source": [
    "# plot the loss\n",
    "plt.plot(r.history['loss'], label='train loss')\n",
    "plt.plot(r.history['val_loss'], label='val loss')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "plt.savefig('LossVal_loss')\n",
    "\n",
    "# plot the accuracy\n",
    "plt.plot(r.history['accuracy'], label='train acc')\n",
    "plt.plot(r.history['val_accuracy'], label='val acc')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "plt.savefig('AccVal_acc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save it as a h5 file\n",
    "\n",
    "\n",
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "model.save('model_vgg19.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "y_pred = model.predict(test_set)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[9.99876857e-01, 1.23175341e-04],\n",
       "       [9.99977112e-01, 2.29190919e-05],\n",
       "       [7.58346558e-01, 2.41653457e-01],\n",
       "       [9.99925494e-01, 7.45595753e-05],\n",
       "       [9.90784764e-01, 9.21520963e-03],\n",
       "       [9.12076458e-02, 9.08792377e-01],\n",
       "       [2.70295113e-01, 7.29704857e-01],\n",
       "       [3.21944878e-02, 9.67805505e-01],\n",
       "       [9.62613881e-01, 3.73861678e-02],\n",
       "       [5.13265312e-01, 4.86734688e-01],\n",
       "       [9.87143576e-01, 1.28563549e-02],\n",
       "       [9.97780263e-01, 2.21971911e-03],\n",
       "       [9.32238042e-01, 6.77619576e-02],\n",
       "       [9.21115577e-01, 7.88843632e-02],\n",
       "       [3.17853913e-02, 9.68214571e-01],\n",
       "       [1.00000000e+00, 9.47071488e-09],\n",
       "       [2.65438944e-01, 7.34561086e-01],\n",
       "       [9.99419808e-01, 5.80202264e-04],\n",
       "       [9.40651655e-01, 5.93483634e-02],\n",
       "       [9.85742450e-01, 1.42575456e-02],\n",
       "       [9.99954581e-01, 4.54339461e-05],\n",
       "       [9.99656916e-01, 3.43117106e-04],\n",
       "       [5.88945560e-02, 9.41105425e-01],\n",
       "       [9.99902725e-01, 9.72729686e-05],\n",
       "       [7.31766939e-01, 2.68233061e-01],\n",
       "       [9.99747813e-01, 2.52151629e-04],\n",
       "       [1.64933771e-01, 8.35066259e-01],\n",
       "       [9.99608934e-01, 3.91100359e-04],\n",
       "       [9.99930501e-01, 6.94626651e-05],\n",
       "       [9.82600868e-01, 1.73991676e-02],\n",
       "       [9.97824430e-01, 2.17563682e-03],\n",
       "       [8.57747495e-02, 9.14225221e-01],\n",
       "       [8.22690725e-01, 1.77309304e-01],\n",
       "       [2.20711201e-01, 7.79288828e-01],\n",
       "       [1.74620345e-01, 8.25379610e-01],\n",
       "       [9.97595489e-01, 2.40448676e-03],\n",
       "       [9.78304744e-01, 2.16952953e-02],\n",
       "       [9.96270061e-01, 3.72986798e-03],\n",
       "       [9.99968529e-01, 3.14996905e-05],\n",
       "       [2.06163585e-01, 7.93836474e-01],\n",
       "       [2.74875015e-01, 7.25125015e-01],\n",
       "       [6.29736423e-01, 3.70263547e-01],\n",
       "       [7.74357736e-01, 2.25642264e-01],\n",
       "       [9.99867320e-01, 1.32690737e-04],\n",
       "       [9.60264862e-01, 3.97351012e-02],\n",
       "       [7.71383643e-01, 2.28616387e-01],\n",
       "       [6.15290999e-01, 3.84708971e-01],\n",
       "       [9.99967098e-01, 3.28774731e-05],\n",
       "       [9.95145261e-01, 4.85474942e-03],\n",
       "       [1.08196318e-01, 8.91803682e-01],\n",
       "       [3.59025478e-01, 6.40974522e-01],\n",
       "       [1.10499725e-01, 8.89500201e-01],\n",
       "       [2.25538373e-01, 7.74461687e-01],\n",
       "       [9.98749137e-01, 1.25089986e-03],\n",
       "       [1.90371588e-01, 8.09628427e-01],\n",
       "       [9.37200725e-01, 6.27992526e-02],\n",
       "       [9.99367177e-01, 6.32850570e-04],\n",
       "       [9.99963284e-01, 3.66732384e-05],\n",
       "       [9.48564351e-01, 5.14356568e-02],\n",
       "       [9.56201553e-01, 4.37984206e-02],\n",
       "       [6.51602149e-02, 9.34839785e-01],\n",
       "       [9.99999046e-01, 1.00051784e-06],\n",
       "       [9.98620391e-01, 1.37962191e-03],\n",
       "       [9.47624370e-02, 9.05237496e-01],\n",
       "       [7.12222219e-01, 2.87777781e-01],\n",
       "       [4.08830613e-01, 5.91169357e-01],\n",
       "       [4.01257932e-01, 5.98742008e-01],\n",
       "       [9.99981642e-01, 1.84092059e-05],\n",
       "       [9.86927807e-01, 1.30722430e-02],\n",
       "       [9.73069012e-01, 2.69310307e-02],\n",
       "       [9.92525339e-01, 7.47464644e-03],\n",
       "       [4.22180533e-01, 5.77819526e-01],\n",
       "       [3.74090314e-01, 6.25909686e-01],\n",
       "       [9.00554836e-01, 9.94452089e-02],\n",
       "       [9.96229827e-01, 3.77019821e-03],\n",
       "       [8.69540453e-01, 1.30459592e-01],\n",
       "       [9.18236852e-01, 8.17631558e-02],\n",
       "       [6.71503171e-02, 9.32849705e-01],\n",
       "       [2.67355323e-01, 7.32644677e-01],\n",
       "       [9.99998689e-01, 1.25849306e-06],\n",
       "       [9.99991894e-01, 8.13550105e-06],\n",
       "       [9.63819861e-01, 3.61801200e-02],\n",
       "       [1.12400115e-01, 8.87599885e-01],\n",
       "       [8.96893084e-01, 1.03106916e-01],\n",
       "       [9.99994040e-01, 5.97917688e-06],\n",
       "       [9.99433100e-01, 5.66851115e-04],\n",
       "       [9.99959230e-01, 4.08172818e-05],\n",
       "       [9.99471962e-01, 5.28042321e-04],\n",
       "       [1.00907192e-01, 8.99092853e-01],\n",
       "       [7.78602958e-01, 2.21397042e-01],\n",
       "       [9.42606330e-01, 5.73936440e-02],\n",
       "       [9.56334770e-02, 9.04366493e-01],\n",
       "       [7.15143263e-01, 2.84856737e-01],\n",
       "       [3.28363180e-01, 6.71636820e-01],\n",
       "       [1.33568943e-01, 8.66431057e-01],\n",
       "       [7.44434819e-02, 9.25556600e-01],\n",
       "       [9.26322997e-01, 7.36770183e-02],\n",
       "       [9.69936788e-01, 3.00631654e-02],\n",
       "       [4.12148356e-01, 5.87851644e-01],\n",
       "       [9.98996079e-01, 1.00392464e-03],\n",
       "       [9.97383654e-01, 2.61637894e-03],\n",
       "       [9.99999642e-01, 3.66045072e-07],\n",
       "       [8.30568254e-01, 1.69431791e-01],\n",
       "       [1.25899151e-01, 8.74100864e-01],\n",
       "       [6.11705780e-02, 9.38829422e-01],\n",
       "       [9.99969840e-01, 3.01911859e-05],\n",
       "       [9.97462153e-01, 2.53788382e-03],\n",
       "       [8.31490874e-01, 1.68509126e-01],\n",
       "       [2.56192029e-01, 7.43807971e-01],\n",
       "       [9.99974728e-01, 2.52405061e-05],\n",
       "       [7.60781288e-01, 2.39218742e-01],\n",
       "       [5.35193384e-01, 4.64806587e-01],\n",
       "       [9.99709666e-01, 2.90352647e-04],\n",
       "       [2.36094102e-01, 7.63905883e-01],\n",
       "       [9.99740064e-01, 2.59921653e-04],\n",
       "       [9.99999285e-01, 6.80445339e-07],\n",
       "       [1.00000000e+00, 8.55684501e-09],\n",
       "       [9.99842644e-01, 1.57280505e-04],\n",
       "       [9.69608068e-01, 3.03919483e-02],\n",
       "       [9.99734938e-01, 2.65098090e-04],\n",
       "       [8.61145318e-01, 1.38854623e-01],\n",
       "       [8.84838045e-01, 1.15161963e-01],\n",
       "       [1.26957521e-01, 8.73042524e-01],\n",
       "       [1.08776897e-01, 8.91223073e-01],\n",
       "       [9.85367537e-01, 1.46324970e-02],\n",
       "       [9.99420404e-01, 5.79623622e-04],\n",
       "       [2.22981453e-01, 7.77018547e-01],\n",
       "       [1.97749451e-01, 8.02250564e-01],\n",
       "       [9.99945760e-01, 5.42549496e-05],\n",
       "       [2.38410935e-01, 7.61589050e-01],\n",
       "       [9.18569207e-01, 8.14308450e-02],\n",
       "       [9.98411298e-01, 1.58868567e-03],\n",
       "       [1.78226024e-01, 8.21774006e-01],\n",
       "       [1.95776328e-01, 8.04223716e-01]], dtype=float32)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "y_pred = np.argmax(y_pred, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0,\n",
       "       1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1,\n",
       "       1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0,\n",
       "       1, 0, 0, 1, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0,\n",
       "       0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 1, 0, 0,\n",
       "       1, 1], dtype=int64)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.preprocessing import image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=load_model('model_vgg19.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "img=image.load_img('Dataset/Test/Uninfected/2.png',target_size=(224,224))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[0., 0., 0.],\n",
       "        [0., 0., 0.],\n",
       "        [0., 0., 0.],\n",
       "        ...,\n",
       "        [0., 0., 0.],\n",
       "        [0., 0., 0.],\n",
       "        [0., 0., 0.]],\n",
       "\n",
       "       [[0., 0., 0.],\n",
       "        [0., 0., 0.],\n",
       "        [0., 0., 0.],\n",
       "        ...,\n",
       "        [0., 0., 0.],\n",
       "        [0., 0., 0.],\n",
       "        [0., 0., 0.]],\n",
       "\n",
       "       [[0., 0., 0.],\n",
       "        [0., 0., 0.],\n",
       "        [0., 0., 0.],\n",
       "        ...,\n",
       "        [0., 0., 0.],\n",
       "        [0., 0., 0.],\n",
       "        [0., 0., 0.]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[0., 0., 0.],\n",
       "        [0., 0., 0.],\n",
       "        [0., 0., 0.],\n",
       "        ...,\n",
       "        [0., 0., 0.],\n",
       "        [0., 0., 0.],\n",
       "        [0., 0., 0.]],\n",
       "\n",
       "       [[0., 0., 0.],\n",
       "        [0., 0., 0.],\n",
       "        [0., 0., 0.],\n",
       "        ...,\n",
       "        [0., 0., 0.],\n",
       "        [0., 0., 0.],\n",
       "        [0., 0., 0.]],\n",
       "\n",
       "       [[0., 0., 0.],\n",
       "        [0., 0., 0.],\n",
       "        [0., 0., 0.],\n",
       "        ...,\n",
       "        [0., 0., 0.],\n",
       "        [0., 0., 0.],\n",
       "        [0., 0., 0.]]], dtype=float32)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x=image.img_to_array(img)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(224, 224, 3)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "x=x/255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 224, 224, 3)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x=np.expand_dims(x,axis=0)\n",
    "img_data=preprocess_input(x)\n",
    "img_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.01155142, 0.98844856]], dtype=float32)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(img_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "a=np.argmax(model.predict(img_data), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uninfected\n"
     ]
    }
   ],
   "source": [
    "if(a==1):\n",
    "    print(\"Uninfected\")\n",
    "else:\n",
    "    print(\"Infected\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
